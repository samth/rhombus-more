#lang rhombus

import:
  racket/math
  racket/format:
    rename:
      #{~a} ~to a
  #{2htdp}/image:
    rename:
      #{above/align} ~to above_align
  #{2htdp}/universe:
    rename:
      #{to-draw} ~to draw
      #{on-key} ~to key
  "draw-neuron.rkt":
    no_prefix
  racket/base:
    prefix r
  #{test-engine}/#{racket-tests}:
    prefix check
    rename:
      #{check-expect} ~to expect
      #{check-within} ~to within
//====== Glue code ======

// A Formula is one of:
// - "a0"
// - "a1"
// - "a2"

class Env(bias::Number,weight1::Number,weight2::Number)

// eval : Formula Env -> Number
fun eval(f,env::Env):
  match f
  | "a0": env.bias
  | "a1": env.weight1
  | "a2": env.weight2

//====== A perceptron ======

// sigmoid : Number -> Number
// convert a number between -infinity and +infinity to a number
// between -1 and 1
//check.within(sigmoid(34), 1, 0.1)
//check.within(sigmoid(-99), -1, 0.1)
//check.within(sigmoid(0), 0, 0.1)
fun sigmoid(t::Number):
  -1+(2/(1+exp(-t)))
//(define (sigmoid t)
//  (+ -1 (* 2 (/ 1 (+ 1 (exp (- t)))))))

// An Env is (make-env Number Number Number)
//(define-struct env [bias weight1 weight2])

// perceptron : Env Number Number -> Number
// a neuron that takes input from two other neurons
fun perceptron(env::Env, x, y):
  sigmoid(env.bias + x * env.weight1 + y * env.weight2)

// make-random-env : Anything -> Env
// randomly initialize an Env with perceptron parameters
fun random_env() :: Env:
  Env(r.random(5) - 2, r.random(5) - 2, r.random(5) - 2)

val myenv: random_env()

//====== Training a perceptron ======

// perceptron-loss : Env Number Number Number -> Number
// the penalty imposed on the perceptron by a training example
// whose inputs are x and y and whose desired output is a
fun perceptron_loss(env, x, y, a):
  math.sqr(perceptron(env, x, y) - a)
  
// total-perceptron-loss : Env -> Number
// the penalty imposed on the perceptron by the 4 training examples for NAND
fun total_perceptron_loss(env):
  perceptron_loss(env, -.9, -.9, +.9)
    + perceptron_loss(env, -.9, +.9, +.9)
    + perceptron_loss(env, +.9, -.9, +.9)
    + perceptron_loss(env, +.9, +.9, -.9)


total_perceptron_loss(myenv)

// diff-sigmoid : Number -> Number
// the derivative of sigmoid
fun diff_sigmoid(t):
  (1 - math.sqr(sigmoid(t))) / 2

// grad-perceptron-loss : Env Number Number Number -> Env
// the gradient of perceptron-loss
fun grad_perceptron_loss(env, x, y, a):
  val backprop: 2 * (perceptron(env,x,y) - a)
                  * diff_sigmoid(env.bias
                                   + x * env.weight1 
                                   + y * env.weight2)
  Env(backprop, x*backprop, y*backprop)



fun perceptron_step(env :: Env):
  r.foldr(fun(grad :: Env, env :: Env):
            Env(env.bias - .2 * grad.bias,
                env.weight1 - .2 * grad.weight1,
                env.weight2 - .2 * grad.weight2),
          env,
          [grad_perceptron_loss(env, -.9, -.9, +.9),
           grad_perceptron_loss(env, -.9, +.9, +.9),
           grad_perceptron_loss(env, +.9, -.9, +.9),
           grad_perceptron_loss(env, +.9, +.9, -.9)])

fun run(f,v,n):
  match n
  |0: v
  |_: run(f,(f(v)),n-1)
  
// perceptron-step : Env -> Env
// adjust the parameters to minimize total-perceptron-loss
// by gradient descent

//====== Animating perceptron training ======

// perceptron-draw : Env -> Image

fun perceptron_draw(env::Env):
  image.above_align(
    "left",
    image.beside(
      draw_neurons([NeuronLayout(50,200,"x"),
                    NeuronLayout(50,50,"y"),
                    NeuronLayout(250,125,"a"),],
                   draw_weights(env,
                                [Layout(250,195,250,125,"a0"),
                                 Layout( 50,200,250,125,"a1"),
                                 Layout( 50, 50,250,125,"a2")],
                                image.rectangle(325,285,"solid","white"),
                                eval)),
      draw_results(fun (x,y): perceptron(env,x,y)),
      image.rectangle(30,0,"solid","white")),
    image.text(format.a(total_perceptron_loss(env)), 20, "black")
  )


fun // would be nice to have one declaration of the type
| perceptron_key(env, "z"): Env(env.bias - 1, env.weight1, env.weight2)
| perceptron_key(env, "x"): Env(env.bias + 1, env.weight1, env.weight2)
| perceptron_key(env, "a"): Env(env.bias, env.weight1 - 1, env.weight2)
| perceptron_key(env, "s"): Env(env.bias, env.weight1 + 1, env.weight2)
| perceptron_key(env, "q"): Env(env.bias, env.weight1, env.weight2 - 1)
| perceptron_key(env, "w"): Env(env.bias, env.weight1, env.weight2 + 1)
| perceptron_key(env, " "): perceptron_step(env)
| perceptron_key(env, _):   env

if "x"
| 2
|  3


big_bang(myenv,
         universe.draw,
         perceptron_draw,
         universe.key,
         perceptron_key)